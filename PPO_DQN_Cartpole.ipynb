{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9uRrUMLmQXU"
   },
   "source": [
    "# SC3000 Assignment 1: Pole Balancing\n",
    "## Done by:\n",
    "1. Luar Shui Yan (U2221566E)\n",
    "2. Tan Yong Jie (U2222722B)\n",
    "\n",
    "## Contributions:\n",
    "1. Luar Shui Yan\n",
    "- Researched PPO, DQN and various other RL models\n",
    "- Implemented and tested PPO on the problem statement\n",
    "- Made evaluation and conclusion on the problem\n",
    "\n",
    "2. Tan Yong Jie\n",
    "- Tested viability of DQN on the Cartpole problem\n",
    "- Tested and debugged model training codes\n",
    "- Made evaluative feedback on the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPxI6DCrfr-y"
   },
   "source": [
    "## Problem Statement Summary\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart. In this project, we will develop a Reinforcement Learning (RL) agent. The trained agent makes the decision to push the cart to the left or right based on the cart position, velocity, and the pole angle, angular velocity.\n",
    "\n",
    "\n",
    "### Action Space\n",
    "The action is an *ndarray* with shape (1,) which can take values {0, 1} indicating pushing the cart to the left or right, respectively. Note that the velocity that is reduced or increased by the applied force is not fixed and it depends on the angle the pole is pointing. The center of gravity of the pole varies the amount of energy needed to move the cart underneath it.\n",
    "\n",
    "\n",
    "### State Space\n",
    "We define *observation* as a state (they are used interchangeably here). The observation is an *ndarray* with shape (4,) with the values corresponding to the following positions and velocities:\n",
    "\n",
    "| **Observation[n]** | **Observation**       | **Min**             | **Max**           |\n",
    "| ------- | --------------------- | ------------------- | ----------------- |\n",
    "| **0**   | Cart Position         | \\-4.8               | 4.8               |\n",
    "| **1**   | Cart Velocity         | \\-Inf               | Inf               |\n",
    "| **2**   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
    "| **3**   | Pole Angular Velocity | \\-Inf               | Inf               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALjgKkiffr-6"
   },
   "source": [
    "## Objective\n",
    "\n",
    "Balance the pole for at least 500 states per episode.\n",
    "\n",
    "The pole is said to be balanced if:\n",
    "* -12° <= Pole Angle <= 12°\n",
    "* Cart Position <= ±2.4 (center of the cart reaches the edge of the display)\n",
    "\n",
    "Violation to any of the two conditions results in an unbalanced pole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQXNz9d2fr-8"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCoV0UAWfr-8"
   },
   "source": [
    "We did research on the following RL methods:\n",
    "\n",
    "1. Proximal Policy Optimization (PPO)\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Stable and reliable performance.\n",
    "- Efficient data use.\n",
    "\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Relatively complex implementation.\n",
    "- Requires careful tuning.\n",
    "\n",
    "\n",
    "\n",
    "2. Deep Q-Network (DQN)\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Simple and intuitive.\n",
    "- Good for discrete action spaces.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Struggles with continuous spaces.\n",
    "- Sample efficiency can be low.\n",
    "\n",
    "\n",
    "3. Soft Actor-Critic (SAC)\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Handles continuous action spaces well.\n",
    "- High sample efficiency.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- More complex than DQN.\n",
    "- Requires careful hyperparameter tuning.\n",
    "\n",
    "4. Trust Region Policy Optimization (TRPO)\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Stable learning updates.\n",
    "- Good for complex control tasks.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Computationally expensive.\n",
    "- Implementation is non-trivial.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Below are the articles we referred to for research\n",
    "\n",
    "Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2022). Proximal Policy Optimization (PPO) Explained. Towards Data Science. Retrieved from https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b\n",
    "\n",
    "M. Gupta. (2023). Deep Q-Networks (DQN) Explained with Examples and Codes in Reinforcement Learning. Medium. Retrieved from https://medium.com/data-science-in-your-pocket/deep-q-networks-dqn-explained-with-examples-and-codes-in-reinforcement-learning-928b97efa792\n",
    "\n",
    "V.V. Kumar. (2019). Soft Actor-Critic Demystified. Towards Data Science. Retrieved from https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665\n",
    "\n",
    "J. SChulman. (2017). Trust Region Policy Optimization. Papers with Code. Retrieved from https://paperswithcode.com/method/trpo#:~:text=Trust%20Region%20Policy%20Optimization%2C%20or,policy%20update%20at%20each%20iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vDurUqffr-9"
   },
   "source": [
    "### Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eI98wDEOfr--"
   },
   "source": [
    "After considering various factors, we will be using **Proximal Policy Optimization (PPO)** over the other three RL methods. This is because:\n",
    "\n",
    "1. PPO efficiently balances exploration and exploitation, ideal for dynamic environments.\n",
    "2. DQN struggles with continuous action spaces; cartpole requires fine control.\n",
    "3. SAC is overly complex for a relatively simple and well-defined problem.\n",
    "4. TRPO is too computationally intensive for tasks that demand quick adaptations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xntocoFfr--"
   },
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRT-DCN_fr--"
   },
   "source": [
    "Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines. We will be importing the PPO algorithm from here.\n",
    "\n",
    "* Reference & more details: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "* Implementation code of PPO in stable-baseline3: https://github.com/DLR-RM/stable-baselines3/tree/master/stable_baselines3/ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM7QZGI4Nmpf",
    "outputId": "db0cf005-33a0-4c42-8629-8d980e032285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gym) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
      "Requirement already satisfied: stable_baselines3 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.4.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from stable_baselines3) (3.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable_baselines3) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable_baselines3) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable_baselines3) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable_baselines3) (2022.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable_baselines3) (3.6.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from pandas->stable_baselines3) (2022.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable_baselines3) (3.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13->stable_baselines3) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13->stable_baselines3) (1.2.1)\n",
      "Requirement already satisfied: torch in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: shimmy in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: gymnasium>=0.27.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from shimmy) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from shimmy) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (4.11.3)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (4.10.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium>=0.27.0->shimmy) (3.8.0)\n",
      "Requirement already satisfied: moviepy in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (2.19.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (2.28.1)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (63.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\yong jie\\anaconda3\\lib\\site-packages (2.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install stable_baselines3\n",
    "!pip install torch\n",
    "!pip install shimmy\n",
    "!pip install moviepy\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rfk38Otofr-_"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "226RBvOrfr_B"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcs0xci8fr_B",
    "outputId": "7d7b9ef5-a118-4cb5-a159-281e9c90a40c"
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3Y4IJDyfr_B"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uqceq_mfr_C"
   },
   "source": [
    "Check if CUDA device is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKQ4ZDVWfr_C",
    "outputId": "3816c08e-7542-4943-9bb4-04845a2d0e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O1lxEQkfr_E"
   },
   "source": [
    "### Vectorized Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGqbjT_hfr_E"
   },
   "source": [
    "Vectorized Environments are a method for stacking multiple independent environments into a single environment.\n",
    "\n",
    "This provides two benefits:\n",
    "\n",
    "* Agent experience can be collected more quickly\n",
    "* The experience will contain a more diverse range of states, it usually improves exploration\n",
    "\n",
    "Stable-Baselines provides two types of Vectorized Environment:\n",
    "\n",
    "* SubprocVecEnv which run each environment in a separate process\n",
    "* DummyVecEnv which run all environment on the same process\n",
    "In practice, DummyVecEnv is usually faster than SubprocVecEnv because of communication delays that subprocesses have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGcbvGWWfr_F",
    "outputId": "3be0a57d-b32d-4200-b0ed-d469a7fbbdab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yong Jie\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = PPO('MlpPolicy', env, verbose=1, device=\"cuda\") # run this if you have an Nvidia GPU installed\n",
    "model = PPO('MlpPolicy', env, verbose=1, device=\"auto\")   # otherwise run this instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu8pLTz4fr_F"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMKtqAoffr_F"
   },
   "source": [
    "We will begin training the model using a timestep of 30000 actions\n",
    "\n",
    "* total_timesteps: int; i.e. the total number of samples to train on\n",
    "\n",
    "* Addendum: total_timesteps represents a singular interaction cycle within the environment, where an agent performs an action and subsequently receives both a new observation and a reward from the environment. Each cycle, the agent picks an action derived from its current strategy, which the environment processes to produce the next state and reward. This feedback loop aids in refining the agent's policy parameters over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "UdKNv4Hufr_G",
    "outputId": "6a97089b-131d-4874-d254-926c2415db35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2379 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009067798 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.000208   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1421        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804821 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1343        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009696305 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009831186 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007475025 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008775098 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1280       |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00679725 |\n",
      "|    clip_fraction        | 0.0478     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.591     |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    value_loss           | 40.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1272         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097753275 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1266         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052195704 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.1          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1262       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00959371 |\n",
      "|    clip_fraction        | 0.0779     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.553     |\n",
      "|    explained_variance   | 0.853      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.35       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00653   |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182985 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 8.4         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1255       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00287063 |\n",
      "|    clip_fraction        | 0.0175     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.519     |\n",
      "|    explained_variance   | 0.764      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00182   |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1251         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039217817 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | -0.171       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.148        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1247        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010012995 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# total_timesteps is the number of env.steps(action) being run during training\n",
    "model = model.learn(total_timesteps = 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdvACMeEfr_H"
   },
   "source": [
    "## Task 1 (Model Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h8mSw5CFfr_H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space is:  [[ 0.04748403 -0.01590968 -0.00822803 -0.01000173]]\n",
      "Action taken is:  [1]\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "action, _ = model.predict(observation)\n",
    "print(\"Observation space is: \", observation)\n",
    "print(\"Action taken is: \", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDOmfNRyfr_I"
   },
   "source": [
    "## Task 2 (Average Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq3KFeGbfr_J"
   },
   "source": [
    "* We ran the trained agent for 100 episodes, and we displayed the score that the agent received for each episode\n",
    "\n",
    "* Then, we calculated the average score of that the agent received for the 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QKvVpuxXfr_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 ;   Score: [500.]\n",
      "Episode: 2 ;   Score: [500.]\n",
      "Episode: 3 ;   Score: [500.]\n",
      "Episode: 4 ;   Score: [500.]\n",
      "Episode: 5 ;   Score: [500.]\n",
      "Episode: 6 ;   Score: [500.]\n",
      "Episode: 7 ;   Score: [500.]\n",
      "Episode: 8 ;   Score: [500.]\n",
      "Episode: 9 ;   Score: [500.]\n",
      "Episode: 10 ;   Score: [500.]\n",
      "Episode: 11 ;   Score: [500.]\n",
      "Episode: 12 ;   Score: [500.]\n",
      "Episode: 13 ;   Score: [500.]\n",
      "Episode: 14 ;   Score: [500.]\n",
      "Episode: 15 ;   Score: [500.]\n",
      "Episode: 16 ;   Score: [500.]\n",
      "Episode: 17 ;   Score: [500.]\n",
      "Episode: 18 ;   Score: [500.]\n",
      "Episode: 19 ;   Score: [500.]\n",
      "Episode: 20 ;   Score: [500.]\n",
      "Episode: 21 ;   Score: [500.]\n",
      "Episode: 22 ;   Score: [500.]\n",
      "Episode: 23 ;   Score: [500.]\n",
      "Episode: 24 ;   Score: [500.]\n",
      "Episode: 25 ;   Score: [500.]\n",
      "Episode: 26 ;   Score: [500.]\n",
      "Episode: 27 ;   Score: [500.]\n",
      "Episode: 28 ;   Score: [500.]\n",
      "Episode: 29 ;   Score: [500.]\n",
      "Episode: 30 ;   Score: [500.]\n",
      "Episode: 31 ;   Score: [500.]\n",
      "Episode: 32 ;   Score: [500.]\n",
      "Episode: 33 ;   Score: [500.]\n",
      "Episode: 34 ;   Score: [500.]\n",
      "Episode: 35 ;   Score: [500.]\n",
      "Episode: 36 ;   Score: [500.]\n",
      "Episode: 37 ;   Score: [500.]\n",
      "Episode: 38 ;   Score: [500.]\n",
      "Episode: 39 ;   Score: [500.]\n",
      "Episode: 40 ;   Score: [500.]\n",
      "Episode: 41 ;   Score: [500.]\n",
      "Episode: 42 ;   Score: [500.]\n",
      "Episode: 43 ;   Score: [500.]\n",
      "Episode: 44 ;   Score: [500.]\n",
      "Episode: 45 ;   Score: [500.]\n",
      "Episode: 46 ;   Score: [500.]\n",
      "Episode: 47 ;   Score: [500.]\n",
      "Episode: 48 ;   Score: [500.]\n",
      "Episode: 49 ;   Score: [500.]\n",
      "Episode: 50 ;   Score: [500.]\n",
      "Episode: 51 ;   Score: [500.]\n",
      "Episode: 52 ;   Score: [500.]\n",
      "Episode: 53 ;   Score: [500.]\n",
      "Episode: 54 ;   Score: [500.]\n",
      "Episode: 55 ;   Score: [500.]\n",
      "Episode: 56 ;   Score: [500.]\n",
      "Episode: 57 ;   Score: [500.]\n",
      "Episode: 58 ;   Score: [500.]\n",
      "Episode: 59 ;   Score: [500.]\n",
      "Episode: 60 ;   Score: [500.]\n",
      "Episode: 61 ;   Score: [500.]\n",
      "Episode: 62 ;   Score: [500.]\n",
      "Episode: 63 ;   Score: [500.]\n",
      "Episode: 64 ;   Score: [500.]\n",
      "Episode: 65 ;   Score: [500.]\n",
      "Episode: 66 ;   Score: [500.]\n",
      "Episode: 67 ;   Score: [500.]\n",
      "Episode: 68 ;   Score: [500.]\n",
      "Episode: 69 ;   Score: [500.]\n",
      "Episode: 70 ;   Score: [500.]\n",
      "Episode: 71 ;   Score: [500.]\n",
      "Episode: 72 ;   Score: [500.]\n",
      "Episode: 73 ;   Score: [500.]\n",
      "Episode: 74 ;   Score: [500.]\n",
      "Episode: 75 ;   Score: [500.]\n",
      "Episode: 76 ;   Score: [500.]\n",
      "Episode: 77 ;   Score: [500.]\n",
      "Episode: 78 ;   Score: [500.]\n",
      "Episode: 79 ;   Score: [500.]\n",
      "Episode: 80 ;   Score: [500.]\n",
      "Episode: 81 ;   Score: [500.]\n",
      "Episode: 82 ;   Score: [500.]\n",
      "Episode: 83 ;   Score: [500.]\n",
      "Episode: 84 ;   Score: [500.]\n",
      "Episode: 85 ;   Score: [500.]\n",
      "Episode: 86 ;   Score: [500.]\n",
      "Episode: 87 ;   Score: [500.]\n",
      "Episode: 88 ;   Score: [500.]\n",
      "Episode: 89 ;   Score: [500.]\n",
      "Episode: 90 ;   Score: [500.]\n",
      "Episode: 91 ;   Score: [500.]\n",
      "Episode: 92 ;   Score: [500.]\n",
      "Episode: 93 ;   Score: [500.]\n",
      "Episode: 94 ;   Score: [500.]\n",
      "Episode: 95 ;   Score: [500.]\n",
      "Episode: 96 ;   Score: [500.]\n",
      "Episode: 97 ;   Score: [500.]\n",
      "Episode: 98 ;   Score: [500.]\n",
      "Episode: 99 ;   Score: [500.]\n",
      "Average score is  [500.]\n"
     ]
    }
   ],
   "source": [
    "sum_episode_scores = []\n",
    "\n",
    "for episode in range(1, 100):    ## total 10 episodes\n",
    "    score = 0                   ## reward init\n",
    "    obs = env.reset()         ## observations\n",
    "    done = False                ## episode completes will make done True\n",
    "    state = 0\n",
    "\n",
    "    while True:\n",
    "        action = model.predict(obs)[0]\n",
    "        n_state, reward, done, info = env.step(action)      ## apply action\n",
    "        if (abs(n_state[0][0]) > 2.4 or abs(n_state[0][2]) > 0.209):\n",
    "            break\n",
    "        if state == 500:\n",
    "            break\n",
    "        obs = n_state\n",
    "        score += reward\n",
    "        state += 1\n",
    "\n",
    "    print('Episode:', episode, ';   Score:', score)\n",
    "    sum_episode_scores.append(score)\n",
    "\n",
    "\n",
    "print(\"Average score is \", sum(sum_episode_scores) / len(sum_episode_scores))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz-zVgN6fr_J"
   },
   "source": [
    "* We then plotted the score of each episode onto a graph and from the graph, we can see that our trained agent performs well on each of the 100 episodes, with only a few outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "om41JsSifr_K"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot([1,2,3,4])\n",
    "plt.plot(sum_episode_scores)\n",
    "plt.title(\"Cumulative reward for each episode\")\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcKLCb0Kfr_K"
   },
   "source": [
    "## Task 3 (1 Episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTXKJ6BRfr_K"
   },
   "source": [
    "* Task 3 requires us to render one of the episodes played by our PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qYUKDwHvfr_L"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import RecordVideo\n",
    "from IPython.display import HTML, Video\n",
    "from IPython import display as ipythondisplay\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def show_video():\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data=''''''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UrSbFtFifr_M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find video\n"
     ]
    }
   ],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "env = RecordVideo(env, './video')\n",
    "\n",
    "observation = env.reset()[0]\n",
    "total_reward = 0\n",
    "for _ in range(500):  # Loop for a maximum of 500 steps\n",
    "    action = model.predict(observation)[0]  \n",
    "    print(env.step(action))\n",
    "    observation, reward, done, info, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8YbXYW8Cfr_N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward is  434.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Episode reward is \", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6FMXZVUfr_O"
   },
   "source": [
    "## Further Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJNe_Dkffr_O"
   },
   "source": [
    "Let us examine how good PPO is in terms of total timesteps taken to train in order to achieve a relatively good average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Giaf2HNQfr_O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yong Jie\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 5000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.1     |\n",
      "|    ep_rew_mean     | 25.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 2325     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.5       |\n",
      "|    ep_rew_mean          | 28.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1639       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00845978 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | -0.00722   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.1        |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    value_loss           | 64         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.9        |\n",
      "|    ep_rew_mean          | 37.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1490        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010773156 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "Training model for 5000 timesteps completed\n",
      "Average score for 5000 timesteps is 70.35\n",
      "Training model for 10000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.7     |\n",
      "|    ep_rew_mean     | 20.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 2379     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 25.6         |\n",
      "|    ep_rew_mean          | 25.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1670         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095342565 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | 2.66e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.79         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.2         |\n",
      "|    ep_rew_mean          | 33.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1514         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099457605 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.9        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1423        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011187041 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.9         |\n",
      "|    ep_rew_mean          | 60.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069367816 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "Training model for 10000 timesteps completed\n",
      "Average score for 10000 timesteps is 143.24\n",
      "Training model for 15000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.5     |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 2416     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.9        |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1657        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008480318 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.000178    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.82        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.4        |\n",
      "|    ep_rew_mean          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009449217 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.0835      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.5         |\n",
      "|    ep_rew_mean          | 49.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1401         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077446913 |\n",
      "|    clip_fraction        | 0.0683       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.642       |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.2         |\n",
      "|    ep_rew_mean          | 64.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081947185 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    value_loss           | 68           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.3        |\n",
      "|    ep_rew_mean          | 74.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006434097 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 86.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.3        |\n",
      "|    ep_rew_mean          | 88.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005797816 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 105          |\n",
      "|    ep_rew_mean          | 105          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1268         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060532615 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.578       |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00966     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "Training model for 15000 timesteps completed\n",
      "Average score for 15000 timesteps is 303.98\n",
      "Training model for 20000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.1     |\n",
      "|    ep_rew_mean     | 24.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 2294     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | 26.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124104 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00573    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.7        |\n",
      "|    ep_rew_mean          | 33.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009339632 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48          |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009146379 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.7        |\n",
      "|    ep_rew_mean          | 62.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1281        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010653108 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.4       |\n",
      "|    ep_rew_mean          | 76.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1255       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553773 |\n",
      "|    clip_fraction        | 0.046      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.584     |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 69.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.4         |\n",
      "|    ep_rew_mean          | 93.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1245         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048271744 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00941     |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 111          |\n",
      "|    ep_rew_mean          | 111          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1238         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051289075 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 129        |\n",
      "|    ep_rew_mean          | 129        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1233       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843096 |\n",
      "|    clip_fraction        | 0.0847     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.595     |\n",
      "|    explained_variance   | 0.84       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.27       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    value_loss           | 30.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1230        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007233625 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "Training model for 20000 timesteps completed\n",
      "Average score for 20000 timesteps is 391.1\n",
      "Training model for 25000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | 21.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 2273     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.5        |\n",
      "|    ep_rew_mean          | 28.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813731 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.000114   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.8        |\n",
      "|    ep_rew_mean          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1392        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221976 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.0814      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 45.3         |\n",
      "|    ep_rew_mean          | 45.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070709176 |\n",
      "|    clip_fraction        | 0.084        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.5        |\n",
      "|    ep_rew_mean          | 60.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010232839 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76          |\n",
      "|    ep_rew_mean          | 76          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005403164 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 63.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1258         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055003557 |\n",
      "|    clip_fraction        | 0.0744       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.599       |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | 107          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1246         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069337897 |\n",
      "|    clip_fraction        | 0.092        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 124        |\n",
      "|    ep_rew_mean          | 124        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1239       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00541777 |\n",
      "|    clip_fraction        | 0.0438     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.569     |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.5       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00928   |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 144          |\n",
      "|    ep_rew_mean          | 144          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1231         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036278684 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.49         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 162        |\n",
      "|    ep_rew_mean          | 162        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1228       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00569536 |\n",
      "|    clip_fraction        | 0.0604     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.579     |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.84       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00923   |\n",
      "|    value_loss           | 12.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | 177          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1226         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046477662 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 195         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1225        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004515355 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "Training model for 25000 timesteps completed\n",
      "Average score for 25000 timesteps is 450.51\n",
      "Training model for 30000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | 21.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 2366     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.9        |\n",
      "|    ep_rew_mean          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009118847 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00923    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.38        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.8        |\n",
      "|    ep_rew_mean          | 34.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1422        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009867414 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.1        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008398779 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.6         |\n",
      "|    ep_rew_mean          | 64.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1328         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057072444 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81           |\n",
      "|    ep_rew_mean          | 81           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083726095 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 59.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.7         |\n",
      "|    ep_rew_mean          | 95.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1286         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036592123 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 113         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009079994 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 130         |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438751 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1252        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006526417 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 167         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1249        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002640801 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 186         |\n",
      "|    ep_rew_mean          | 186         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1243        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006691937 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011229124 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    value_loss           | 4.84        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 220          |\n",
      "|    ep_rew_mean          | 220          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1235         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067954655 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 239          |\n",
      "|    ep_rew_mean          | 239          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1233         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040611643 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | -0.0121      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000829    |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "Training model for 30000 timesteps completed\n",
      "Average score for 30000 timesteps is 490.18\n"
     ]
    }
   ],
   "source": [
    "avg_score_per_dif_timesteps = []\n",
    "env_name = 'CartPole-v1'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "for i in range(5000, 35000, 5000):\n",
    "    print(f\"Training model for {i} timesteps started\")\n",
    "    model = PPO('MlpPolicy', env, verbose=1, device=\"cuda\")\n",
    "    model.learn(total_timesteps=i, progress_bar=False)\n",
    "    print(f\"Training model for {i} timesteps completed\")\n",
    "\n",
    "    sum_episode_scores = []\n",
    "    for episode in range(1, 101):  # Running 100 episodes\n",
    "        score = 0\n",
    "        obs = env.reset()[0]\n",
    "        done = False\n",
    "        while not done and score < 500:\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, done, info, _ = env.step(action)\n",
    "            score += reward\n",
    "        sum_episode_scores.append(score)\n",
    "\n",
    "    avg = sum(sum_episode_scores) / len(sum_episode_scores)\n",
    "    print(f\"Average score for {i} timesteps is {round(avg, 2)}\")\n",
    "    avg_score_per_dif_timesteps.append(round(avg, 2))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70.35, 143.24, 303.98, 391.1, 450.51, 490.18]\n"
     ]
    }
   ],
   "source": [
    "print(avg_score_per_dif_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zrlXYBnmfr_P"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_score_per_dif_timesteps)\n",
    "x_labels = ['5000', '10000', '15000', '20000', '25000', '30000']\n",
    "plt.title(\"Average reward per 100 episode for each X timesteps used for training\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.xticks(range(len(x_labels)), x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RaSA-otfr_Q"
   },
   "source": [
    "As the graph shown, PPO is able to get an acceptable average scores of above 300 with only 15000 timesteps\n",
    "At 25000 timesteps, PPO is able to achieve perfect score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeJsQQzNfvpr"
   },
   "source": [
    "## Appendix: (Attempted) Deep Q-learning\n",
    "\n",
    "In this section we will show our attempt with DQN.\n",
    "\n",
    "\n",
    "\n",
    "The following sources guided and helped us in the implementation of DQN, and taught us a lot, despite not settling with DQN ultimately.\n",
    "\n",
    "Schwarz, L. (2021). Explanation and Implementation of DQN with Tensorflow and Keras. Retrieved from lukasschwarz.de\n",
    "\n",
    "FreeCodeCamp. (n.d.). Improvements in Deep Q Learning: Dueling Double DQN, Prioritized Experience Replay, and fixed…. Retrieved from freecodecamp.org\n",
    "\n",
    "PyTorch. (n.d.). Reinforcement Learning (DQN) Tutorial — PyTorch Tutorials 2.2.1+cu121 documentation. Retrieved from pytorch.org\n",
    "\n",
    "Hugging Face. (n.d.). Deep Q-Learning with Space Invaders. Retrieved from huggingface.co\n",
    "\n",
    "Towards Data Science. (n.d.). Welcome to Deep Reinforcement Learning Part 1: DQN. Retrieved from towardsdatascience.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"CartPole-v1\")\n",
    "\n",
    "learning_rate = 0.2\n",
    "discount = 1\n",
    "episodes = 30000\n",
    "observation_space = [40, 40, 50, 50]\n",
    "window_size = np.array([0.25, 0.25, 0.05, 0.5])\n",
    "exploration_rate = 1\n",
    "exploration_rate_minimum = 0.05\n",
    "exploration_decay = (exploration_rate - exploration_rate_minimum) / 12500\n",
    "rewards_history = []\n",
    "\n",
    "observation = environment.reset()\n",
    "\n",
    "q_table = np.zeros((observation_space + [environment.action_space.n]))\n",
    "\n",
    "def calculate_discrete_state(state):\n",
    "    discrete_state = state / window_size + np.array([15, 10, 1, 10])\n",
    "    return tuple(discrete_state.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Exploration Rate: 0.999924\n",
      "Average Episode Reward: 0.016\n",
      "Exploration Rate: 0.923924000000035\n",
      "Average Episode Reward: 23.513\n",
      "Episode: 2000\n",
      "Exploration Rate: 0.8885080000000514\n",
      "Average Episode Reward: 26.462\n",
      "Exploration Rate: 0.8569680000000659\n",
      "Average Episode Reward: 28.2\n",
      "Episode: 4000\n",
      "Exploration Rate: 0.8248960000000807\n",
      "Average Episode Reward: 30.773\n",
      "Exploration Rate: 0.7912280000000962\n",
      "Average Episode Reward: 33.596\n",
      "Episode: 6000\n",
      "Exploration Rate: 0.7607520000001102\n",
      "Average Episode Reward: 35.616\n",
      "Exploration Rate: 0.7251080000001267\n",
      "Average Episode Reward: 39.939\n",
      "Episode: 8000\n",
      "Exploration Rate: 0.6903760000001427\n",
      "Average Episode Reward: 43.698\n",
      "Exploration Rate: 0.6540480000001594\n",
      "Average Episode Reward: 47.63\n",
      "Episode: 10000\n",
      "Exploration Rate: 0.6161240000001769\n",
      "Average Episode Reward: 53.254\n",
      "Exploration Rate: 0.5823800000001924\n",
      "Average Episode Reward: 54.811\n",
      "Episode: 12000\n",
      "Exploration Rate: 0.5444560000002099\n",
      "Average Episode Reward: 60.216\n",
      "Exploration Rate: 0.5062280000002275\n",
      "Average Episode Reward: 67.613\n",
      "Episode: 14000\n",
      "Exploration Rate: 0.46526400000022095\n",
      "Average Episode Reward: 77.683\n",
      "Exploration Rate: 0.42886000000021113\n",
      "Average Episode Reward: 82.786\n",
      "Episode: 16000\n",
      "Exploration Rate: 0.38956800000020053\n",
      "Average Episode Reward: 90.767\n",
      "Exploration Rate: 0.35027600000018994\n",
      "Average Episode Reward: 95.762\n",
      "Episode: 18000\n",
      "Exploration Rate: 0.3082480000001786\n",
      "Average Episode Reward: 105.203\n",
      "Exploration Rate: 0.26584000000016716\n",
      "Average Episode Reward: 116.747\n",
      "Episode: 20000\n",
      "Exploration Rate: 0.22670000000016513\n",
      "Average Episode Reward: 122.33\n",
      "Exploration Rate: 0.1798080000001696\n",
      "Average Episode Reward: 142.759\n"
     ]
    }
   ],
   "source": [
    "def train(environment, total_episodes, rate, discount_factor, exploration, decay_rate, strategy_table):\n",
    "    accumulated_reward = 0\n",
    "    previous_average_reward = 0\n",
    "    for ep in range(total_episodes):\n",
    "        state_index = calculate_discrete_state(environment.reset()[0])\n",
    "        finished = False\n",
    "        ep_reward = 0\n",
    "        steps = 0\n",
    "        if ep % 2000 == 0:\n",
    "            print(\"Episode: \" + str(ep))\n",
    "        while not finished:\n",
    "            if np.random.random() > exploration:\n",
    "                action_decision = np.argmax(strategy_table[state_index])\n",
    "            else:\n",
    "                action_decision = np.random.randint(0, environment.action_space.n)\n",
    "            new_state_info = environment.step(action_decision)\n",
    "            new_state = new_state_info[0]\n",
    "            reward = new_state_info[1]\n",
    "            finished = new_state_info[2]\n",
    "            ep_reward += reward\n",
    "            steps += 1\n",
    "            new_state_index = calculate_discrete_state(new_state)\n",
    "            future_max_q = np.max(strategy_table[new_state_index])\n",
    "            current_q_value = strategy_table[state_index + (action_decision,)]\n",
    "            reward = 1 if finished and steps >= 195 else -1 if finished else 0.1\n",
    "\n",
    "            updated_q = (1 - rate) * current_q_value + rate * (reward + discount_factor * future_max_q)\n",
    "            strategy_table[state_index + (action_decision,)] = updated_q\n",
    "\n",
    "            state_index = new_state_index\n",
    "        accumulated_reward += ep_reward\n",
    "        rewards_history.append(ep_reward)\n",
    "\n",
    "        if exploration > 0.05 and ep_reward > previous_average_reward:\n",
    "            exploration -= decay_rate\n",
    "        if ep % 1000 == 0:\n",
    "            print(\"Exploration Rate: \" + str(exploration))\n",
    "            average_ep_reward = accumulated_reward / 1000\n",
    "            print(\"Average Episode Reward: \" + str(average_ep_reward))\n",
    "            previous_average_reward = average_ep_reward\n",
    "            accumulated_reward = 0\n",
    "            \n",
    "    environment.close()\n",
    "    return strategy_table, rewards_history\n",
    "\n",
    "strategy_table, episode_rewards = train(environment, episodes, learning_rate, discount, exploration_rate, exploration_decay, q_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = environment.reset()\n",
    "print(\"Observation:\", observation[0])\n",
    "discrete_state = calculate_discrete_state(observation[0])\n",
    "action = np.argmax(q_table[discrete_state])\n",
    "print(\"Chosen Action:\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_rewards = []\n",
    "\n",
    "for ep in range(100):\n",
    "    state_index = calculate_discrete_state(environment.reset()[0])\n",
    "    finished = False\n",
    "    ep_reward = 0\n",
    "    while not finished:\n",
    "        action_decision = np.argmax(strategy_table[state_index])\n",
    "        new_state_info = environment.step(action_decision)\n",
    "        new_state = new_state_info[0]\n",
    "        reward = new_state_info[1]\n",
    "        finished = new_state_info[2]\n",
    "        ep_reward += reward\n",
    "        if ep_reward > 500:\n",
    "            finished = True\n",
    "        new_state_index = calculate_discrete_state(new_state)\n",
    "        state_index = new_state_index\n",
    "        if finished:\n",
    "            observation = environment.reset()\n",
    "            state_index = calculate_discrete_state(observation[0])\n",
    "    accumulated_rewards.append(ep_reward)\n",
    "environment.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accumulated_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accumulated_rewards)\n",
    "plt.title('Cumulative reward for each episode')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.xlabel('episode')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXEC1QLfgE8a"
   },
   "source": [
    "In conclusion, PPO is more feasible to solve CartPole-v1 due to several factors:\n",
    "1. Continuous Action Space:\n",
    "\n",
    "The continuous action space of Cartpole implies endless range of potential actions, and DQN in particular struggles in such a setting.\n",
    "\n",
    "2. Sample Efficiency:\n",
    "\n",
    "PPO can give us our desired results in fewer training episodes than other RL methods, most notably DQN\n",
    "\n",
    "3. Training Duration:\n",
    "\n",
    "Cartpole has a continuous action space and RL methods like DQN are forced to discretise it first, degrading its performance compared to PPO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
